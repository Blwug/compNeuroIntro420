#+Title: Introduction to Linear Algebra and Neural Networks
#+Author: Britt Anderson
#+Date: Winter 2022
#+Options: toc:nil ^:nil d:nil 
#+bibliography:/home/britt/gitRepos/masterBib/bayatt.bib
#+csl-style: ./j-neurosci.csl
* Introduction
   :PROPERTIES:
   :CUSTOM_ID: introduction
   :END:
** Goals
Our goal for the next few lessons is to come to understand 
- What is a neural network?
- What mathematics are needed to build a neural network?
- How can neural networks help us understand cognition?

As a first illustration of some of the key ideas we will execute a simple cellular automata rule. 
** Be the Neuron
   :PROPERTIES:
   :CUSTOM_ID: be-the-neuron
   :END:
For this exercise you will need a sheet of graph paper and a *rule*.

Think of this /rule/ as a /mathematical function/: a matching of each possible input to one possible output. You are going to consider a particular grid cell of the graph papers as a metaphorical neuron. That "neuron" decides whether or not to "fire" (in this case firing is to be colored in black and not firing to be left white).  Your rule specifies what the output is for that neuron/grid-cell as a function of it's three inputs: the neighbor to the left, itself, and the neighbor to the right. We view the passage of time as flowing down, so you color in the neuron's state below it. 

#+CAPTION: Automata as a 1D grid with neighbors. For this example the neuron is grid cell "2". You decide whether to color the grid cell below (visualized as the neuron one moment in time later) based on the value of the neighbor to your left, itself, and the neigbhbor to the right. Implement your assigned rule on the piece of graph paper to see what pattern emerges.
#+NAME:   fig:grid.png
[[./grid.png]]

** What are the lessons learned?
1. Repetitive actions are hard. We (humans) make mistakes following even simple rules for a large number of repeated steps. Better to let the computer do it since that is where its strengths lie.
2. Complex global patterns can emerge from local actions. Each neuron is only responding to its immediate right and left yet global structures emerge.
3. These characteristics seem similar to brain activity. Each neuron in the brain is just one of many. Whether a neuron spikes or not is a consequence of its own state and its inputs (like the neighbors in the grid example).
4. From each neuron making a local computation, global patterns of complex activity can emerge.
5. Maybe by programming something similar to this system we can get insights into brain activity.

** Programmatic implementation
To demonstrate how one might take the ideas that we practiced when implementing a cellular automata phycially programmatically, I have coded some of the steps for a visualization in common lisp and show the code here. Because things don't always run so cleanly when breaking the code into snippets inside an orgmode file and using emacs, if you decide to adapt or test this code you should use the [[file:cellular-automata.lisp]].

#+Name: Defining Package
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports none :tangle ./test-tangle.lisp
  ;; need to quickload trivia and str in slime for this to work <2022-01-03 Mon>
(ql:quickload "trivia")
(ql:quickload "zpng")
(ql:quickload "str")

(defpackage #:cellular-automata
  (:nicknames "CA")
  (:use #:cl)
  (:import-from "TRIVIA" "MATCH")
  (:import-from "STR" "PAD")
  (:import-from "ZPNG" "PNG" "DATA-ARRAY" "WRITE-PNG"))

(in-package :ca)
#+end_src

#+Name: Rule Demonstration
#+Caption: A simple rule: nothing changes
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun rule0 (ns) 
	   (match ns
	     ('('w 'w 'w) 'w)
	     ('('w 'w 'b) 'w)
	     ('('w 'b 'w) 'w)
	     ('('b 'w 'w) 'w)
	     ('('w 'b 'b) 'w)
	     ('('b 'w 'b) 'w)
	     ('('b 'b 'w) 'w)
	     ('('b 'b 'b) 'w)))
  #+end_src

The above code snippet shows us how we can view the instructions of what to color as a function that takes input and gives us a unique output. We have three cells to consider, and they can each be one of two values. That means there are $2\times2\times2$ or $8$ cases our rule has to cover. For each of those 8 cases the output can be either of two values so we have $2^8$ possible rules (though you might think that we only have half that many since all white or all black is pretty much the same thing).

We can view each rule as a mapping from one binary number to a 0 or 1. If 'w' is considered a zero then the input "w w w" is 0 0 0. The use of binary numbers gives us a natural order. If we apply the same mapping of w → 0 and b → 1 then then each rule can also be seen as a binary number and exists in a fixed order. We can translate that binary number to our usual base 10 number. For example, when we map each input to w we get the binary number 00000000 and this is 0 in base 10;  "00011110" is 30 [fn:1]. You can also go the other way and convert the number in base 10 representation to a binary list. It may be a bit tedious to figure out the details, but once you do the computer can make the translation over and over without mistake. 

That way we don't have to manually write 256 rules like this:

#+Name: rule:110
#+Caption: Rule 110 for "01101110"
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun rule110 (ns) 
	   (match ns
	     ('('w 'w 'w) 'w)
	     ('('w 'w 'b) 'b)
	     ('('w 'b 'w) 'b)
	     ('('b 'w 'w) 'w)
	     ('('w 'b 'b) 'b)
	     ('('b 'w 'b) 'b)
	     ('('b 'b 'w) 'b)
	     ('('b 'b 'b) 'w)))
  #+end_src
  
#+Name: code:make-rule
#+Caption: Automate where you can. This is my first (successful) attempt to generate a function that will write its own function to map the outputs based on the number of the rule. It basically writes a function like the ones we have above. It substitutes the output for the color that goes with the number of the rule. It should be possible to make the matching part more concise and not require me to manually call each element, but the perfect can be the enemy of the good. Often times it is better to get something that works up and running. If you need to later on you can make it more efficient or elgant. 
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun make-rule (rule-no)
    (flet ((white-or-black? (in-char)
	     (if (string= in-char #\0) 'w 'b)))
    (let ((test-char (reverse (str:pad 8 (write-to-string rule-no :base 2) :pad-char "0" :pad-side :left))))
      (lambda (ns)
      (match ns
	 ('(w w w) (white-or-black? (elt test-char 0)))
	 ('(w w b) (white-or-black? (elt test-char 1)))
	 ('(w b w) (white-or-black? (elt test-char 2)))
	 ('(w b b) (white-or-black? (elt test-char 3)))
	 ('(b w w) (white-or-black? (elt test-char 4)))
	 ('(b w b) (white-or-black? (elt test-char 5)))
	 ('(b b w) (white-or-black? (elt test-char 6)))
	 ('(b b b) (white-or-black? (elt test-char 7))))))))
#+end_src

#+Caption: Demonstrating how to make and use a rule.
#+begin_src lisp :tangle ./test-tangle.lisp :exports code :eval never
  (defparameter r110 (make-rule 110))
  
  (funcall r110 '('b 'w 'b))
#+end_src


#+Caption: To make our computer automata we need to create the top-row and then run our automata rule along that row, and then down the rows. To handle the edges we will "wrap" the neighborhoods. 
#+begin_src lisp :tangle ./test-tangle.lisp :exports code 
(defun top-row (n)
  (multiple-value-bind
	(how-many-start how-many-end)
      (if (evenp n)
	  (values (- (/ n 2) 1) (/ n 2))
	  (values (/ (- n 1) 2)  (/ (- n 1) 2)))
    (append (make-list how-many-start :initial-element 'w) (cons 'b nil) (make-list how-many-end :initial-element 'w))))

(defun pad-front (in-list)
  (cons (elt in-list (- (length in-list) 1))
	(subseq in-list 0 2)))

(defun pad-end (in-list)
  (append (subseq in-list (- (length in-list) 2) (length in-list)) (list (first in-list))))

(defun crawl-cols (which-rule in-list)
  (do*  ((next-row (list (funcall which-rule (pad-front in-list))))
	 (when-to-quit (length in-list))
	 (start 0 (+ 1 start))
	 (stop 3 (+ 1 stop))
	 (patt (funcall which-rule (subseq in-list start stop)) (funcall which-rule (subseq in-list start stop))))
	 ((= stop when-to-quit) (nreverse (append (list (funcall which-rule (pad-end in-list)) patt) next-row)))
    (push patt next-row)))

(defun build-rows (which-rule &key (ncols 200) (nrows 200))
  (let ((lol (list (top-row ncols))))
    (dotimes (rs (- nrows 1) (nreverse lol))
      (push (crawl-cols which-rule (elt lol 0)) lol)
      )))
    
#+End_src

#+RESULTS:
: BUILD-ROWS

#+Caption: Printing. Lastly we need a mechanism for seeing our automata in action. I decided to render the data to a png using a pre-exising packge.
#+begin_src lisp :tangle ./test-tangle.lisp :exports code
(defun rule-num-to-png (rule-num file-name
			&key (xsize 200)
			  (ysize 200))
  (let* ((which-rule (make-rule rule-num))
	 (rule-dat (build-rows which-rule :ncols xsize :nrows ysize))
	 (pic (make-instance 'png :width  xsize
				  :height ysize
				  :color-type :grayscale))
	 (image-data (data-array pic)))
    (dotimes (ri (length rule-dat) (write-png pic file-name))
      (let ((cur-row (elt rule-dat ri)))
	(dotimes (ci  (length cur-row))
	  (setf (aref image-data ri ci 0) (if (equal (elt cur-row ci) 'w) 255 0)))))))
#+end_src

#+RESULTS:
: RULE-NUM-TO-PNG

#+Caption: Seeing the results
#+begin_src lisp :exports both :results file graphics :file "r110.png"
(rule-num-to-png 110 "r110.png" :xsize 400 :ysize 600)
#+end_src

#+RESULTS:
[[file:r110.png]]


** The activity :class_exercise:

1. We need to have something to start with. Put a black square in the center middle of your graph paper. [fn:2] You need to do this, because I will call on a random subset of you to exhibit your pattern. 
2. Send in the chat the number for the rule you are going to follow. You can pick any rule you want except for 0 or 110, or the number that anyone before you has already selected.
3. Follow your rule and work across and down coloring each row based on the update of the cell above it.
4. Do enough rows to get a sense of the pattern, and then message in the chat that you are done.
5. *Save your image*. If it is a piece of paper take a picture of it. If it is a spreadsheet take a screen grab. You will have to submit that to the dropbox on learn for credit for today's activity.
6. A *homework* for this activity will be to reproduce your rule as a bit of computer code. You will use any programming language (other than lisp) to write a function like the one I have written for outputting the color of a square based on the input of its neighbors.
NB. For the class in Winter 2022 I decided *not* to make this a homework. 


** Cellular Automata
   :PROPERTIES:
   :CUSTOM_ID: cellular-automata
   :END:
:course-development:
Use the sketch package in Lisp (or something similar to make a little function that draw the output of a rule.
:END:

Cellular automata provide some basic lessons that lay the ground work for thinking about neural networks. 

*** Local Decisions Can Produce Interesting Global Effects

[[https://plato.stanford.edu/entries/cellular-automata/supplement.html][SEP: The 256 Rules]]

[[https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life][Game of Life]] (wikipedia link)

You can think of each cell in the grid as a neuron. It receives input via it's dendrites and it has a current state (e.g. the internal voltage). Based on its current voltage and the input to the neuron it does or does not fire. With our automata the cell's current color was its voltage and the color of the neighbors on either side were the inputs to our grid cell's dendrites.

*** You can think of cells (or units or neurons) as functions or computations

*** Automata are themselves viewed as a model of the brain

John Von Neumann *Automata and the Brain*

   Commentary by
   [[http://www.ams.org/bull/1958-64-03/S0002-9904-1958-10214-1/S0002-9904-1958-10214-1.pdf][Claude Shannon (pdf)]]

   [[https://complexityexplorer.s3.amazonaws.com/supplemental_materials/5.6+Artificial+Life/The+Computer+and+The+Brain_text.pdf][Copy (pdf)]] of the
   book: [[https://ocul-wtl.primo.exlibrisgroup.com/permalink/01OCUL_WTL/vk29fk/alma994863683505162][The Computer and the Brain]]

Stephen Wolfram [[http://www.wolframscience.com][thinks]] automata explain everything

* What Math Underlies Neural Networks?
  :PROPERTIES:
  :CUSTOM_ID: what-math-underlies-neural-networks
  :END:

** Linear Algebra
   :PROPERTIES:
   :CUSTOM_ID: linear-algebra
   :END:

*** Objects and Operations
1. Vectors
2. Matrices
3. Scalars
4. Addition
5. Multiplication (scalar and matrix)
6. Transposition
7. Inverse

*** Adding Matrices                                          :class_exercise:

Two definitions of a vector:

1) It is an object (arrow) with magnitude and direction
2) It is a (by convention) column of numbers

For different purposes one or the other definition may prove more convenient.

A matrix can be considered as a collection of vectors or, in our case, as a rectangular (2-D) collection of numbers.

**** Activity
Using your preferred programming language figure out how to construct an array/matrix.

Make two of them and make them the same size (what is the /size/ of a matrix?).

Add them together in both orders (A + B and B + A)

Then do the same for multiplication. Note that there are particular requirements for the sizes of matrices in order from the to be able to be multiplied one versus another and very strict requirements for being able to be multiplied in both directions.

What is the name for the operation when A*B = B*A?

To get you started [[https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.array-creation.html][here]] are many different ways to create array in python and [[https://www.tutorialspoint.com/r/r_matrices.htm][R]].

*** Common Notational Conventions for Vectors and Matrices
   :PROPERTIES:
   :CUSTOM_ID: notation
   :END:

Vectors tend to be notated as /lower case/ letters, often in bold, such
as $\mathbf{a}$. They are also occasionally represented with little
arrows on top such as $\overrightarrow{\textbf{a}}$.

Matrices tend to be notated as /upper case/ letters, typically in bold,
such as $\mathbf{M}$.

Good things to know: what is an /inner product/? How do you compute it in your preferred programming language?

*** Another Homework

Submit a simple program that accepts two matrices, checks if they are of compatible sizes, and then computes their inner product. 

* What is a Neural Network?
  :PROPERTIES:
  :CUSTOM_ID: what-is-a-neural-network
  :END:

What is a Neural Network? It is a brain inspired computational approach
in which "neurons" compute functions of their inputs and pass on a
/weighted/ proportion to the next neuron in the chain.

#+CAPTION: Simple schematic of the basics of a neural network. This is an image for a single neuron. The input has three elements and each of these connects to the same neuron ("Node 1"). The activity at those nodes is filtered by the weights, which are specific for each of the inputs. These three processed inputs are combined to generate the output from this neuron. For multiple layers this output becomes an input for the next neuron along the chain. 
#+NAME:   fig:grid.png

[[./nn.png]]


** Non-linearities
   The spiking of a neuron is non-linear. The increase in voltage with increasing input is not a straight line. To emulate this, and sometimes just to make the math easier, there is often further processing on the output of the neuron before it becomes the input to the next layer. In its simplest form this takes the form of a /thresholding/ operation. We did something very much like this when we set a threshold for the spike in our integrate and fire model.

#+Name: eqn:threshold-neuron
#+Caption: A simple equation to capture the thresholding of our simple one neuron with three inputs.
\begin{equation}
\mbox{if } I_1 \times w_{1,1} + I_2 \times w_{2,1} + I_3 \times w_{3,1} > \Theta \mbox{ then } Output = 1
\end{equation}

What this equation shows is that Inputs (the $I$ s) are passed to the first layer. A weighted
sum (inner product) is computed as an intermediate value. The weighted sum is fed into a threshold function that compares the value to a threshold ($\Theta$), and passes on the value 1 if it
is greater than the threshold and 0 (sometimes $-1$ is chosen) otherwise.

** Questions:
   :PROPERTIES:
   :CUSTOM_ID: questions
   :END:

1. What, geometrically speaking, is a plane?
2. What is a hyperplane?
3. What is linearly separability and how does that relate to planes and
   hyperplanes?

** Examples
   :PROPERTIES:
   :CUSTOM_ID: examples
   :END:

*** AND
    :PROPERTIES:
    :CUSTOM_ID: and
    :END:

#+BEGIN_SRC python :results graphics output file :file "and.png" :tangle ./test-tangle.lisp :exports file
  import matplotlib 
  import matplotlib.pyplot as p
  cs = ["#ff0000","#ff0000","#ff0000","#008000"]
  p.scatter([0, 1, 0, 1],[0,0,1,1],color=cs,s = 60)
  p.savefig("and.png")
#+END_SRC

#+RESULTS:
[[file:and.png]]

*** XOR
    :PROPERTIES:
    :CUSTOM_ID: xor
    :END:

#+BEGIN_SRC python :results graphics output file :file "xor.png" :tangle ./test-tangle.lisp :exports file
  import matplotlib 
  import matplotlib.pyplot as p
  cs = ["#ff0000", "#008000",  "#008000", "#ff0000"]
  p.scatter([0, 1, 0, 1],[0,0,1,1],color=cs,s = 60)
  p.savefig("xor.png")
#+END_SRC

#+RESULTS:
[[file:xor.png]]

*** Optional Reading

This short [[https://media.nature.com/m685/nature-assets/nbt/journal/v26/n2/images/nbt1386-F1.gif][article]] provides a nice example of linear separability and some basics of what a neural network is. 

* Connections
  Can neural networks encode logic? Is the processing zeros and ones enough to capture the richness of human intellectual activity?

  In fact there is a long tradition of representing human thought as the consequence of some sort of calculation of two values (true or false). If you have two values you can swap out 1's and 0's for the true and false in your calculation. They even seem to obey similar laws. If you the conjunction (AND) of two true things it is only true when both are true. If you take T = 1, then T ∧ T is the same as $1~\times~1$.

  In the next section we will build up a simple threshold neural unit and try to calculate some of these truth functions with our neuron. We will build simple neurons for truth tables (like those that follow), and string them together into an argument. Then we can feed values of T and F into our network and let it calculate the XOR problem.
  
** Boolean Logic
   :PROPERTIES:
   :CUSTOM_ID: boolean-logic
   :END:

- George Boole, Author of the /Laws of Thought/

  1. Read the [[https://archive.org/details/investigationofl00boolrich][book]] on Archive.org
  2. Read about [[https://plato.stanford.edu/entries/boole/#LifWor][George Boole]].

** First Order Logic - Truth Tables
1. Or
   #+Name: Or
   #+Caption: Or
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  0 |
   |    0 |    1 |  1 |
   |    1 |    0 |  1 |
   |    1 |    1 |  1 |

2. And
   #+Name: And
   #+Caption: And
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  0 |
   |    0 |    1 |  0 |
   |    1 |    0 |  0 |
   |    1 |    1 |  1 |


 3. Nand
    #+Name: Nand
    #+Caption: Nand
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  1 |
   |    0 |    1 |  0 |
   |    1 |    0 |  0 |
   |    1 |    1 |  0 |
    

* Footnotes
[fn:2] If you don't have graph paper just draw a grid on any handy sheet of paper. If you don't have a piece of paper open up a spreadsheet on your computer and just type in 0's and 1's to represent white and black (or color the cells if you know how to do that).  

[fn:1] 30 
