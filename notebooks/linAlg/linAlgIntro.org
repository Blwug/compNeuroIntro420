#+Title: Introduction to Linear Algebra and Neural Networks
#+Author: Britt Anderson
#+Date: Winter 2022
#+Options: toc:nil ^:nil d:nil 
#+bibliography:/home/britt/gitRepos/masterBib/bayatt.bib
#+csl-style: ./j-neurosci.csl
* Introduction
   :PROPERTIES:
   :CUSTOM_ID: introduction
   :END:
** Goals
Our goal for the next few lessons is to come to understand 
- What is a neural network?
- What mathematics are needed to build a neural network?
- How can neural networks help us understand cognition?

As a first illustration of some of the key ideas we will execute a simple cellular automata rule. 
** Be the Neuron
   :PROPERTIES:
   :CUSTOM_ID: be-the-neuron
   :END:
For this exercise you will need a sheet of graph paper and a *rule*.

Think of this /rule/ as a /mathematical function/: a matching of each possible input to one possible output. You are going to consider a particular grid cell of the graph papers as a metaphorical neuron. That "neuron" decides whether or not to "fire" (in this case firing is to be colored in black and not firing to be left white).  Your rule specifies what the output is for that neuron/grid-cell as a function of it's three inputs: the neighbor to the left, itself, and the neighbor to the right. We view the passage of time as flowing down, so you color in the neuron's state below it. 

#+CAPTION: Automata as a 1D grid with neighbors. For this example the neuron is grid cell "2". You decide whether to color the grid cell below (visualized as the neuron one moment in time later) based on the value of the neighbor to your left, itself, and the neigbhbor to the right. Implement your assigned rule on the piece of graph paper to see what pattern emerges.
#+NAME:   fig:grid.png
[[./grid.png]]

** What are the lessons learned?
1. Repetitive actions are hard. We (humans) make mistakes following even simple rules for a large number of repeated steps. Better to let the computer do it since that is where its strengths lie.
2. Complex global patterns can emerge from local actions. Each neuron is only responding to its immediate right and left yet global structures emerge.
3. These characteristics seem similar to brain activity. Each neuron in the brain is just one of many. Whether a neuron spikes or not is a consequence of its own state and its inputs (like the neighbors in the grid example).
4. From each neuron making a local computation, global patterns of complex activity can emerge.
5. Maybe by programming something similar to this system we can get insights into brain activity.

** Programmatic implementation
To demonstrate how one might take the ideas that we practiced when implementing a cellular automata phycially programmatically, I have coded some of the steps for a visualization in common lisp and show the code here. Because things don't always run so cleanly when breaking the code into snippets inside an orgmode file and using emacs, if you decide to adapt or test this code you should use the [[file:cellular-automata.lisp]].

#+Name: Defining Package
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports none :tangle ./test-tangle.lisp
  ;; need to quickload trivia and str in slime for this to work <2022-01-03 Mon>
(ql:quickload "trivia")
(ql:quickload "zpng")
(ql:quickload "str")

(defpackage #:cellular-automata
  (:nicknames "CA")
  (:use #:cl)
  (:import-from "TRIVIA" "MATCH")
  (:import-from "STR" "PAD")
  (:import-from "ZPNG" "PNG" "DATA-ARRAY" "WRITE-PNG"))

(in-package :ca)
#+end_src

#+Name: Rule Demonstration
#+Caption: A simple rule: nothing changes
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun rule0 (ns) 
	   (match ns
	     ('('w 'w 'w) 'w)
	     ('('w 'w 'b) 'w)
	     ('('w 'b 'w) 'w)
	     ('('b 'w 'w) 'w)
	     ('('w 'b 'b) 'w)
	     ('('b 'w 'b) 'w)
	     ('('b 'b 'w) 'w)
	     ('('b 'b 'b) 'w)))
  #+end_src

The above code snippet shows us how we can view the instructions of what to color as a function that takes input and gives us a unique output. We have three cells to consider, and they can each be one of two values. That means there are $2\times2\times2$ or $8$ cases our rule has to cover. For each of those 8 cases the output can be either of two values so we have $2^8$ possible rules (though you might think that we only have half that many since all white or all black is pretty much the same thing).

We can view each rule as a mapping from one binary number to a 0 or 1. If 'w' is considered a zero then the input "w w w" is 0 0 0. The use of binary numbers gives us a natural order. If we apply the same mapping of w → 0 and b → 1 then then each rule can also be seen as a binary number and exists in a fixed order. We can translate that binary number to our usual base 10 number. For example, when we map each input to w we get the binary number 00000000 and this is 0 in base 10;  "00011110" is 30 [fn:1]. You can also go the other way and convert the number in base 10 representation to a binary list. It may be a bit tedious to figure out the details, but once you do the computer can make the translation over and over without mistake. 

That way we don't have to manually write 256 rules like this:

#+Name: rule:110
#+Caption: Rule 110 for "01101110"
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun rule110 (ns) 
	   (match ns
	     ('('w 'w 'w) 'w)
	     ('('w 'w 'b) 'b)
	     ('('w 'b 'w) 'b)
	     ('('b 'w 'w) 'w)
	     ('('w 'b 'b) 'b)
	     ('('b 'w 'b) 'b)
	     ('('b 'b 'w) 'b)
	     ('('b 'b 'b) 'w)))
  #+end_src
  
#+Name: code:make-rule
#+Caption: Automate where you can. This is my first (successful) attempt to generate a function that will write its own function to map the outputs based on the number of the rule. It basically writes a function like the ones we have above. It substitutes the output for the color that goes with the number of the rule. It should be possible to make the matching part more concise and not require me to manually call each element, but the perfect can be the enemy of the good. Often times it is better to get something that works up and running. If you need to later on you can make it more efficient or elgant. 
#+begin_src lisp :results silent :tangle ./test-tangle.lisp :exports code
(defun make-rule (rule-no)
    (flet ((white-or-black? (in-char)
	     (if (string= in-char #\0) 'w 'b)))
    (let ((test-char (reverse (str:pad 8 (write-to-string rule-no :base 2) :pad-char "0" :pad-side :left))))
      (lambda (ns)
      (match ns
	 ('(w w w) (white-or-black? (elt test-char 0)))
	 ('(w w b) (white-or-black? (elt test-char 1)))
	 ('(w b w) (white-or-black? (elt test-char 2)))
	 ('(w b b) (white-or-black? (elt test-char 3)))
	 ('(b w w) (white-or-black? (elt test-char 4)))
	 ('(b w b) (white-or-black? (elt test-char 5)))
	 ('(b b w) (white-or-black? (elt test-char 6)))
	 ('(b b b) (white-or-black? (elt test-char 7))))))))
#+end_src

#+Caption: Demonstrating how to make and use a rule.
#+begin_src lisp :tangle ./test-tangle.lisp :exports code :eval never
  (defparameter r110 (make-rule 110))
  
  (funcall r110 '('b 'w 'b))
#+end_src


#+Caption: To make our computer automata we need to create the top-row and then run our automata rule along that row, and then down the rows. To handle the edges we will "wrap" the neighborhoods. 
#+begin_src lisp :tangle ./test-tangle.lisp :exports code 
(defun top-row (n)
  (multiple-value-bind
	(how-many-start how-many-end)
      (if (evenp n)
	  (values (- (/ n 2) 1) (/ n 2))
	  (values (/ (- n 1) 2)  (/ (- n 1) 2)))
    (append (make-list how-many-start :initial-element 'w) (cons 'b nil) (make-list how-many-end :initial-element 'w))))

(defun pad-front (in-list)
  (cons (elt in-list (- (length in-list) 1))
	(subseq in-list 0 2)))

(defun pad-end (in-list)
  (append (subseq in-list (- (length in-list) 2) (length in-list)) (list (first in-list))))

(defun crawl-cols (which-rule in-list)
  (do*  ((next-row (list (funcall which-rule (pad-front in-list))))
	 (when-to-quit (length in-list))
	 (start 0 (+ 1 start))
	 (stop 3 (+ 1 stop))
	 (patt (funcall which-rule (subseq in-list start stop)) (funcall which-rule (subseq in-list start stop))))
	 ((= stop when-to-quit) (nreverse (append (list (funcall which-rule (pad-end in-list)) patt) next-row)))
    (push patt next-row)))

(defun build-rows (which-rule &key (ncols 200) (nrows 200))
  (let ((lol (list (top-row ncols))))
    (dotimes (rs (- nrows 1) (nreverse lol))
      (push (crawl-cols which-rule (elt lol 0)) lol)
      )))
    
#+End_src

#+RESULTS:
: BUILD-ROWS

#+Caption: Printing. Lastly we need a mechanism for seeing our automata in action. I decided to render the data to a png using a pre-exising packge.
#+begin_src lisp :tangle ./test-tangle.lisp :exports code
(defun rule-num-to-png (rule-num file-name
			&key (xsize 200)
			  (ysize 200))
  (let* ((which-rule (make-rule rule-num))
	 (rule-dat (build-rows which-rule :ncols xsize :nrows ysize))
	 (pic (make-instance 'png :width  xsize
				  :height ysize
				  :color-type :grayscale))
	 (image-data (data-array pic)))
    (dotimes (ri (length rule-dat) (write-png pic file-name))
      (let ((cur-row (elt rule-dat ri)))
	(dotimes (ci  (length cur-row))
	  (setf (aref image-data ri ci 0) (if (equal (elt cur-row ci) 'w) 255 0)))))))
#+end_src

#+RESULTS:
: RULE-NUM-TO-PNG

#+Caption: Seeing the results
#+begin_src lisp :exports both :results file graphics :file "r110.png"
(rule-num-to-png 110 "r110.png" :xsize 400 :ysize 600)
#+end_src

#+RESULTS:
[[file:r110.png]]


** The activity :class_exercise:

1. We need to have something to start with. Put a black square in the center middle of your graph paper. [fn:2] You need to do this, because I will call on a random subset of you to exhibit your pattern. 
2. Send in the chat the number for the rule you are going to follow. You can pick any rule you want except for 0 or 110, or the number that anyone before you has already selected.
3. Follow your rule and work across and down coloring each row based on the update of the cell above it.
4. Do enough rows to get a sense of the pattern, and then message in the chat that you are done.
5. *Save your image*. If it is a piece of paper take a picture of it. If it is a spreadsheet take a screen grab. You will have to submit that to the dropbox on learn for credit for today's activity.
6. A *homework* for this activity will be to reproduce your rule as a bit of computer code. You will use any programming language (other than lisp) to write a function like the one I have written for outputting the color of a square based on the input of its neighbors.
NB. For the class in Winter 2022 I decided *not* to make this a homework. 


** Cellular Automata
As mentioned above, cellular automata demonstrate some basic lessons that we will make use of when thinking about neural networks. One of these points is that there may be simpler representations for complex descriptions. If we can find the right language to translate them into we may get concision and repeatability as by-products. This is demonstrated by the naming convention for the rules of cellular automata: [[https://plato.stanford.edu/entries/cellular-automata/supplement.html][SEP: The 256 Rules]]

In emphasizing that local decisions can produce interesting global effects it may be interesting to examine other similar uses of the cellular automata idea. One famous and visually pleasing one is the [[https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life][Game of Life]].

The analogy of automata to simple neurons may be deeper than at first it appears. Some very famous thinkers connected the two. One of the most brilliant people of all time, John von Neumann, was working on a book about automata and the brain at the time of his death. I have linked to a commentary in case you are interested in reading further ([[http://www.ams.org/bull/1958-64-03/S0002-9904-1958-10214-1/S0002-9904-1958-10214-1.pdf][Claude Shannon (pdf)]]) as well as to a pdf [[https://complexityexplorer.s3.amazonaws.com/supplemental_materials/5.6+Artificial+Life/The+Computer+and+The+Brain_text.pdf][copy]] of the book: [[https://ocul-wtl.primo.exlibrisgroup.com/permalink/01OCUL_WTL/vk29fk/alma994863683505162][The Computer and the Brain]]

A contemporary mathematician and the inventor of the Mathematica software system also believes that cellular automata may be a theory of everything. See what Stephen Wolfram [[http://www.wolframscience.com][thinks]].

* What Math Underlies Neural Networks?
** Linear Algebra
The math at the heart of neural networks and their computer implementation is /linear algebra/. For us, the section of linear algebra we are going to need is mostly limited to vectors, matrices and how to add and multiply them.

*** Some of the Objects and Operations we will need (terminology to learn). 
1. Vectors
2. Matrices
3. Scalars
4. Addition
5. Multiplication (scalar and matrix)
6. Transposition
7. Inverse

*** Adding Matrices                                          :class_exercise:
To gain some hands on familiarity with the manipulation of matrices and vectors we will try to do by hand and in simple programs some of the fundamental operations of addition and multiplication. We will also thereby learn that some of the rules we learned for numbers (such as a * b = b * a) do not always apply in other mathematical realms.

Two ways to think about what a vector is:

1) It is an object (arrow) with magnitude and direction
2) It is a (by convention) column of numbers

For different purposes one or the other definition may prove more convenient.

A matrix can be considered as a collection of vectors or, in our case, as a rectangular (2-D) collection of numbers.

**** Activity
Using your preferred programming language figure out how to construct an array/matrix.

Make two arrays and make them the same size (what is the /size/ of a matrix?).

Add them together in both orders (A + B and B + A). How does one add an array that itself has numerous different numbers?

Then do the same for multiplication. Note that there are particular requirements for the sizes of matrices in order from the to be able to be multiplied one versus another and very strict requirements for being able to be multiplied in both directions.

What is the name for the operation when A*B = B*A?

To get you started [[https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.array-creation.html][here]] are many different ways to create array in python and [[https://www.tutorialspoint.com/r/r_matrices.htm][R]].

*** Common Notational Conventions for Vectors and Matrices

Vectors tend to be notated as /lower case/ letters, often in bold, such
as $\mathbf{a}$. They are also occasionally represented with little
arrows on top such as $\overrightarrow{\textbf{a}}$.

Matrices tend to be notated as /upper case/ letters, typically in bold,
such as $\mathbf{M}$.

Good things to know: what is an /inner product/? How do you compute it in your preferred programming language?

*** Homework

Submit a simple program that accepts two matrices, checks if they are of compatible sizes, and then computes their inner product. 

* What is a Neural Network?

What is a Neural Network? It is a brain inspired computational approach
in which "neurons" compute functions of their inputs and pass on a
/weighted/ proportion to the next neuron in the chain.

#+CAPTION: Simple schematic of the basics of a neural network. This is an image for a single neuron. The input has three elements and each of these connects to the same neuron ("Node 1"). The activity at those nodes is filtered by the weights, which are specific for each of the inputs. These three processed inputs are combined to generate the output from this neuron. For multiple layers this output becomes an input for the next neuron along the chain. 
#+NAME:   fig:grid.png

[[./nn.png]]


** Non-linearities
   The spiking of a neuron is non-linear. You saw this in both the integrate and fire and Hodgkin and Huxley models you programmed. The lines on those plots your created are not, for the most part, straight. Perhaps the simplest way to incorporate a non-linearity into our artificial neuron is to give it a threshold, like we did for the integrate and fire model. When activity exceeds the threshold (which we will usually designate with a capital Greek Theta $\Theta$) then the neuron is set to 1 and if it is not firing it is set to 0 (like the "w" → 0; "b" → 1 mapping we used for the cellular automata).
   
#+Name: eqn:threshold-neuron
#+Caption: A simple equation to capture the thresholding of our simple one neuron with three inputs.
\begin{equation}
\mbox{if } I_1 \times w_{1,1} + I_2 \times w_{2,1} + I_3 \times w_{3,1} > \Theta \mbox{ then } Output = 1
\end{equation}

What this equation shows is that Inputs (the $I$ s) are passed to a neuron. Those inputs have something like a synapse. That is designated by the w's. Those weights are how tightly the input and internal activity of our artificial neuron is coupled. The reason for all the subscripts is to try and help you see the similarity between this equation and the inner product and matrix multiplication rules you just worked on programming. The activity of the neuron is a sort of internal state, and then based on the comparison of that activity to the threshold you can envision the neuron spiking or not, meaning it has value 1 or 0. Mathematically, the weighted sum is fed into a threshold function that compares the value to a threshold ($\Theta$), and passes on the value 1 if it
is greater than the threshold and 0 (sometimes $-1$ rather than zero is chosen for the inactive state because there are certain computational conveniences in doing so).

** Questions:
1. What, geometrically speaking, is a plane?
2. What is a hyperplane?
3. What is linearly separability and how does that relate to planes and
   hyperplanes?

** Examples of Boolean Functions and How They Map onto our Neural Network Intuitions
*** AND
#+Name: And Function
#+Caption: The "and" is true when both inputs, and only when both inputs, are true.
[[file:and-lisp.png]]

#+Name: Or Function
#+Caption: The "or" is true unless both inputs are false.
[[file:or-lisp.png]]

*** XOR
#+Name: XOR  (also known as exclusive or) Function
#+Caption: The "xor" is true when one or the other, but not both of the inputs are true. It is exclusively an or function
[[file:xor-lisp.png]]

*** Optional Reading

This short [[https://media.nature.com/m685/nature-assets/nbt/journal/v26/n2/images/nbt1386-F1.gif][article]] provides a nice example of linear separability and some basics of what a neural network is. 

* Connections
  Can neural networks encode logic? Is the processing zeros and ones enough to capture the richness of human intellectual activity?

  In fact there is a long tradition of representing human thought as the consequence of some sort of calculation of two values (true or false). If you have two values you can swap out 1's and 0's for the true and false in your calculation. They even seem to obey similar laws. If you the conjunction (AND) of two true things it is only true when both are true. If you take T = 1, then T ∧ T is the same as $1~\times~1$.

  In the next section we will build up a simple threshold neural unit and try to calculate some of these truth functions with our neuron. We will build simple neurons for truth tables (like those that follow), and string them together into an argument. Then we can feed values of T and F into our network and let it calculate the XOR problem.
  
** Boolean Logic
   :PROPERTIES:
   :CUSTOM_ID: boolean-logic
   :END:

- George Boole, Author of the /Laws of Thought/

  1. Read the [[https://archive.org/details/investigationofl00boolrich][book]] on Archive.org
  2. Read about [[https://plato.stanford.edu/entries/boole/#LifWor][George Boole]].

** First Order Logic - Truth Tables
1. Or
   #+Name: Or
   #+Caption: Or
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  0 |
   |    0 |    1 |  1 |
   |    1 |    0 |  1 |
   |    1 |    1 |  1 |

2. And
   #+Name: And
   #+Caption: And
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  0 |
   |    0 |    1 |  0 |
   |    1 |    0 |  0 |
   |    1 |    1 |  1 |


 3. Nand
    #+Name: Nand
    #+Caption: Nand
   | Pr A | Pr B | Or |
   |------+------+----|
   |    0 |    0 |  1 |
   |    0 |    1 |  0 |
   |    1 |    0 |  0 |
   |    1 |    1 |  0 |
    

* Footnotes
[fn:2] If you don't have graph paper just draw a grid on any handy sheet of paper. If you don't have a piece of paper open up a spreadsheet on your computer and just type in 0's and 1's to represent white and black (or color the cells if you know how to do that).  

[fn:1] 30 
